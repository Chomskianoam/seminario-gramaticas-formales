{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parsers de dependencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requerimientos\n",
    "- Python 3\n",
    "- Spacy\n",
    "- NLTK\n",
    "- MaltParser\n",
    "- Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "from nltk import Tree\n",
    "from spacy import displacy \n",
    "from nltk.parse import malt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No poseen distinción entre símbolos no terminales y terminales. Las estructuras representan relaciones de dependencia entre terminales.\n",
    "Ejemplos de parsers de dependencias:\n",
    "* [Projective Dependency Parser de NLTK](https://www.nltk.org/_modules/nltk/parse/projectivedependencyparser.html)\n",
    "* [Maltparser](http://www.maltparser.org/)\n",
    "* SyntaxNet (Estaba alojado en https://opensource.google.com/projects/syntaxnet, como parte de los recursos de la librería para Inteligencia Artificial TensorFlow de Google, pero en este momento no está disponible y [se rumorea](https://github.com/tensorflow/models/issues/8411) que se lo va a mover al github de [google-research](https://github.com/google-research/google-research))\n",
    "* [Dependency parser de Spacy](https://spacy.io/usage/linguistic-features#dependency-parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projective Dependency Parser NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_parser(sentence, grammar):         # define una función llamada dep_parser con dos argumentos\n",
    "    sentence = sentence.lower()            # convierte a minúscula la oración\n",
    "    if sentence.endswith('.'):             # si la oración termina con un punto\n",
    "        sent = re.sub('\\.','',sentence)    # se lo quita\n",
    "    else:                                  # si no\n",
    "        sent = sentence                    # la toma como está\n",
    "    sent = sent.split()                    # divide la oración en palabras\n",
    "    dep_gram = nltk.data.load(grammar, cache=False) # carga la gramática a nltk\n",
    "    dep_gram = nltk.DependencyGrammar.fromstring(dep_gram) # parsea la gramática como gramática de dependencias\n",
    "    pdp = nltk.ProjectiveDependencyParser(dep_gram) # aarga la gramática en el parser\n",
    "    print(dep_gram)                        # imprime mi gramática\n",
    "    for tree in pdp.parse(sent):           # para cada árbol posible en mi gramática para esa oración\n",
    "        print(tree)                        # lo imprime\n",
    "        return(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency grammar with 36 productions\n",
      "  'fuma' -> 'fede'\n",
      "  'fuma' -> 'cata'\n",
      "  'fuma' -> 'julia'\n",
      "  'fuma' -> 'martín'\n",
      "  'fuma' -> 'vicky'\n",
      "  'fuma' -> 'pablo'\n",
      "  'fuma' -> 'juan'\n",
      "  'explotó' -> 'fede'\n",
      "  'explotó' -> 'cata'\n",
      "  'explotó' -> 'julia'\n",
      "  'explotó' -> 'martín'\n",
      "  'explotó' -> 'vicky'\n",
      "  'explotó' -> 'pablo'\n",
      "  'explotó' -> 'globo'\n",
      "  'explotó' -> 'facultad'\n",
      "  'globo' -> 'el'\n",
      "  'tabaco' -> 'el'\n",
      "  'cigarrillo' -> 'el'\n",
      "  'plaza' -> 'la'\n",
      "  'facultad' -> 'la'\n",
      "  'fue' -> 'el'\n",
      "  'fue' -> 'entregado'\n",
      "  'fue' -> 'enviado'\n",
      "  'fue' -> 'fumado'\n",
      "  'fue' -> 'explotado'\n",
      "  'entregado' -> 'por'\n",
      "  'explotado' -> 'por'\n",
      "  'fumado' -> 'por'\n",
      "  'enviado' -> 'por'\n",
      "  'por' -> 'fede'\n",
      "  'por' -> 'cata'\n",
      "  'por' -> 'julia'\n",
      "  'por' -> 'martín'\n",
      "  'por' -> 'vicky'\n",
      "  'por' -> 'pablo'\n",
      "  'por' -> 'facultad'\n"
     ]
    }
   ],
   "source": [
    "#Para correr el Proyective Dependency Parser\n",
    "\n",
    "oracion1 = 'Pablo explotó el globo'    # Define la oración a analizar\n",
    "#grammar = 'gramaticas/DG1.txt'        # establece cuál va a ser mi gramática\n",
    "# !COMENTARIO\n",
    "# acá puse la otra gramática que sugiero\n",
    "grammar = 'gramaticas/DG1_suggest.txt' # establece cuál va a ser mi gramática\n",
    "dep_parser(oracion1, grammar)          # Para correr la función"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Projective Dependency Parser NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npdep_parser(sentence, grammar):                # define una función llamada dep_parser con dos argumentos\n",
    "    sentence = sentence.lower()                     # convierte a minúscula la oración\n",
    "    if sentence.endswith('.'):                      # si la oración termina con un punto\n",
    "        sent = re.sub('\\.',' ',sentence)            # se lo quita\n",
    "    else:                                           # si no\n",
    "        sent = sentence                             # la toma como está\n",
    "    sent = sent.split()                             # divide la oración en palabras\n",
    "    dep_gram = nltk.data.load(grammar, cache=False) # carga la gramática a nltk\n",
    "    dep_gram = nltk.DependencyGrammar.fromstring(dep_gram) # parsea la gramática como gramática de dependencias\n",
    "    pdp = nltk.NonprojectiveDependencyParser(dep_gram) # carga la gramática en el parser\n",
    "    print(sent)\n",
    "    print(dep_gram)                                  # imprime mi gramática\n",
    "    g, = pdp.parse(sent)\n",
    "    print(g.root['word'])\n",
    "    structure = g.tree()\n",
    "    print(structure)\n",
    "    return(structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fede', 'fuma', 'el', 'cigarrillo']\n",
      "Dependency grammar with 37 productions\n",
      "  'fuma' -> 'fede'\n",
      "  'fuma' -> 'cata'\n",
      "  'fuma' -> 'julia'\n",
      "  'fuma' -> 'martín'\n",
      "  'fuma' -> 'vicky'\n",
      "  'fuma' -> 'pablo'\n",
      "  'fuma' -> 'juan'\n",
      "  'fuma' -> 'cigarrillo'\n",
      "  'explotó' -> 'fede'\n",
      "  'explotó' -> 'cata'\n",
      "  'explotó' -> 'julia'\n",
      "  'explotó' -> 'martín'\n",
      "  'explotó' -> 'vicky'\n",
      "  'explotó' -> 'pablo'\n",
      "  'explotó' -> 'globo'\n",
      "  'explotó' -> 'facultad'\n",
      "  'globo' -> 'el'\n",
      "  'tabaco' -> 'el'\n",
      "  'cigarrillo' -> 'el'\n",
      "  'plaza' -> 'la'\n",
      "  'facultad' -> 'la'\n",
      "  'fue' -> 'el'\n",
      "  'fue' -> 'entregado'\n",
      "  'fue' -> 'enviado'\n",
      "  'fue' -> 'fumado'\n",
      "  'fue' -> 'explotado'\n",
      "  'entregado' -> 'por'\n",
      "  'explotado' -> 'por'\n",
      "  'fumado' -> 'por'\n",
      "  'enviado' -> 'por'\n",
      "  'por' -> 'fede'\n",
      "  'por' -> 'cata'\n",
      "  'por' -> 'julia'\n",
      "  'por' -> 'martín'\n",
      "  'por' -> 'vicky'\n",
      "  'por' -> 'pablo'\n",
      "  'por' -> 'facultad'\n",
      "fuma\n",
      "(fuma fede (cigarrillo el))\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"120px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,144.0,120.0\" width=\"144px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">fuma</text></svg><svg width=\"33.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">fede</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.6667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"66.6667%\" x=\"33.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cigarrillo</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">el</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.6667%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
      ],
      "text/plain": [
       "Tree('fuma', ['fede', Tree('cigarrillo', ['el'])])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Para correr el Nonproyective Dependency Parser\n",
    "\n",
    "oracion1 = 'fede fuma el cigarrillo'    # Define la oración a analizar\n",
    "#grammar1 = 'gramaticas/DG1.txt'        # establece cuál va a ser mi gramática\n",
    "# !COMENTARIO\n",
    "# acá puse la otra gramática que sugiero\n",
    "grammar1 = 'gramaticas/DG1_suggest.txt' # establece cuál va a ser mi gramática\n",
    "npdep_parser(oracion1, grammar1)        # Para correr la función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quién', 'fuma', 'el', 'cigarrillo']\n",
      "Dependency grammar with 55 productions\n",
      "  'dijo' -> 'juan'\n",
      "  'dijo' -> 'fede'\n",
      "  'dijo' -> 'cata'\n",
      "  'dijo' -> 'julia'\n",
      "  'dijo' -> 'martín'\n",
      "  'dijo' -> 'vicky'\n",
      "  'dijo' -> 'pablo'\n",
      "  'dijo' -> 'andrés'\n",
      "  'dijo' -> 'mati'\n",
      "  'dijo' -> 'quién' 'el'\n",
      "  'dijo' -> 'la'\n",
      "  'dijo' -> 'un'\n",
      "  'dijo' -> 'una'\n",
      "  'dijo' -> 'que'\n",
      "  'dijo' -> 'qué'\n",
      "  'dijiste' -> 'vos' 'el'\n",
      "  'dijiste' -> 'la'\n",
      "  'dijiste' -> 'un'\n",
      "  'dijiste' -> 'una'\n",
      "  'dijiste' -> 'que'\n",
      "  'dijiste' -> 'qué'\n",
      "  'fuma' -> 'juan'\n",
      "  'fuma' -> 'fede'\n",
      "  'fuma' -> 'cata'\n",
      "  'fuma' -> 'julia'\n",
      "  'fuma' -> 'martín'\n",
      "  'fuma' -> 'vicky'\n",
      "  'fuma' -> 'pablo'\n",
      "  'fuma' -> 'andrés'\n",
      "  'fuma' -> 'mati'\n",
      "  'fuma' -> 'quién'\n",
      "  'fuma' -> 'fede'\n",
      "  'fuma' -> 'cata'\n",
      "  'fuma' -> 'julia'\n",
      "  'fuma' -> 'martín'\n",
      "  'fuma' -> 'vicky'\n",
      "  'fuma' -> 'pablo'\n",
      "  'fuma' -> 'andrés'\n",
      "  'fuma' -> 'mati'\n",
      "  'fuma' -> 'quién' 'el'\n",
      "  'fuma' -> 'la'\n",
      "  'fuma' -> 'un'\n",
      "  'fuma' -> 'una'\n",
      "  'fuma' -> 'qué'\n",
      "  'el' -> 'cigarrillo'\n",
      "  'el' -> 'tabaco'\n",
      "  'la' -> 'pipa'\n",
      "  'la' -> 'barbaridad'\n",
      "  'la' -> 'verdad'\n",
      "  'un' -> 'cigarrillo'\n",
      "  'un' -> 'tabaco'\n",
      "  'una' -> 'pipa'\n",
      "  'una' -> 'verdad'\n",
      "  'una' -> 'barbaridad'\n",
      "  'que' -> 'fuma'\n",
      "fuma\n",
      "(fuma quién (el cigarrillo))\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"120px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,152.0,120.0\" width=\"152px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">fuma</text></svg><svg width=\"36.8421%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">quién</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"18.4211%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"63.1579%\" x=\"36.8421%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">el</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cigarrillo</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"68.4211%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
      ],
      "text/plain": [
       "Tree('fuma', ['quién', Tree('el', ['cigarrillo'])])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Para correr el Nonproyective Dependency Parser\n",
    "\n",
    "oracion2 = 'quién fuma el cigarrillo'  # Define la oración a analizar\n",
    "#oracion2 = 'quién dijo fede que fuma'  # Define la oración a analizar\n",
    "#oracion2 = 'qué dijo fede que fuma'  # Define la oración a analizar\n",
    "# Habría que arreglar la función npdep_parser para que pueda tomar estas dos últimas oraciones\n",
    "grammar2 = 'gramaticas/DG2.txt'       # establece cuál va a ser mi gramática\n",
    "npdep_parser(oracion2, grammar2)        # Para correr la función"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy - Dependency parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nota para quien no tenga la MV: \n",
    "\n",
    "Antes de correr hay que instalar spacy. Con pip3, eso se puede hacer con el comando \n",
    "\n",
    "`pip3 install spacy`\n",
    "\n",
    "Hay que instalar también es_core_news_sm, un modelo entrenado mediante un corpus del español, con el comando\n",
    "\n",
    "`python3 -m spacy download es_core_news_sm`\n",
    "\n",
    "Alternativamente puede probarse de instalar es_core_news_md.\n",
    "\n",
    "`python3 -m spacy download es_core_news_md`\n",
    "\n",
    "En ese caso, para correrlo hay que cambiar en el código de abajo `es_core_news_sm` por `es_core_news_md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gramaticadependencias(sentence):       #Define la función\n",
    "    nlp = spacy.load('es_core_news_sm')    #Carga el modelo entrenado\n",
    "    doc = nlp(sentence)                    #define una variable doc con la oración procesada por el modelo\n",
    "    #for token in doc:               \n",
    "        #print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "        #    [child for child in token.children])\n",
    "    # !COMENTARIO\n",
    "    # esto no aporta mucho, pero podemos mostrar que se puede customizar la visualización\n",
    "    # options = {\"compact\": True, \"bg\": \"#09a3d5\",\"color\": \"white\", \"font\": \"Source Sans Pro\"}\n",
    "    #displacy.render(doc, style='dep', jupyter=True, options=options)\n",
    "    displacy.render(doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !COMENTARIO\n",
    "# ju, comento la celda que sigue porque, claro, no se renderiza nada porque tampoco se le mete ningín input\n",
    "# por ahí lo podemos dejar comentado y lo descomentamos en la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oracion5 = input('Escribí una oración\\n')\n",
    "#gramaticadependencias(oracion5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TEXTO     | DEP  | N_IZQ  | N_DER  | ANCESTROS                      |\n",
      "|=====================================================================|\n",
      "| en        | case |       0|       0| ['casa', 'tomamos']            |\n",
      "| mi        | det  |       0|       0| ['casa', 'tomamos']            |\n",
      "| casa      | obl  |       2|       0| ['tomamos']                    |\n",
      "| tomamos   | ROOT |       1|       2| []                             |\n",
      "| café      | obj  |       0|       1| ['tomamos']                    |\n",
      "| con       | case |       0|       0| ['masitas', 'café', 'tomamos'] |\n",
      "| masitas   | obl  |       1|       0| ['café', 'tomamos']            |\n",
      "| por       | case |       0|       0| ['tarde', 'tomamos']           |\n",
      "| la        | det  |       0|       0| ['tarde', 'tomamos']           |\n",
      "| tarde     | obl  |       2|       0| ['tomamos']                    |\n"
     ]
    }
   ],
   "source": [
    "# !COMENTARIO\n",
    "# creo que también se puede mostrar esto, ¿qué te parece?\n",
    "# si te parece mejor, lo paso a una función\n",
    "# lo puse así no más a ver si te gustaba, si no, lo sacamos\n",
    "\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "doc = nlp(oracion5)\n",
    "root = [token for token in doc if token.head == token][0]\n",
    "print('| {0:10}| {1:5}| {2:7}| {3:7}| {4:30} |'.format('TEXTO','DEP','N_IZQ','N_DER','ANCESTROS'))\n",
    "print('|'+'='*69+'|')\n",
    "for descendant in root.subtree:\n",
    "    assert root is descendant or root.is_ancestor(descendant)\n",
    "    print('| {0:10}| {1:5}| {2:7}| {3:7}| {4:30} |'.format(\n",
    "        descendant.text,\n",
    "        descendant.dep_,\n",
    "        descendant.n_lefts,\n",
    "        descendant.n_rights,\n",
    "        str([ancestor.text for ancestor in descendant.ancestors])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Malt Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrucciones\n",
    "\n",
    "Crear la carpeta malt y adentro bajar los siguientes archivos:\n",
    "- Malt Parser de [http://www.maltparser.org/download.html](http://www.maltparser.org/download.html)\n",
    "- Bajar el modelo entrenado engmalt.poly-1.7 de [http://www.maltparser.org/mco/english_parser/engmalt.html](http://www.maltparser.org/mco/english_parser/engmalt.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-12 17:00:42--  http://www.maltparser.org/mco/english_parser/engmalt.poly-1.7.mco\n",
      "Resolving www.maltparser.org (www.maltparser.org)... 195.74.38.120\n",
      "Connecting to www.maltparser.org (www.maltparser.org)|195.74.38.120|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://www.maltparser.org/mco/english_parser/engmalt.poly-1.7.mco [following]\n",
      "--2022-06-12 17:00:43--  https://www.maltparser.org/mco/english_parser/engmalt.poly-1.7.mco\n",
      "Connecting to www.maltparser.org (www.maltparser.org)|195.74.38.120|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 21556252 (21M) [application/x-troff-man]\n",
      "Saving to: ‘maltparser-1.9.2/engmalt.poly-1.7.mco.2’\n",
      "\n",
      "engmalt.poly-1.7.mc 100%[===================>]  20,56M  1,28MB/s    in 19s     \n",
      "\n",
      "2022-06-12 17:01:03 (1,06 MB/s) - ‘maltparser-1.9.2/engmalt.poly-1.7.mco.2’ saved [21556252/21556252]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !COMENTARIO\n",
    "# Ju, te dejo una sugerencia para la descarga de lo anterior, para que puedan hacerlo\n",
    "# ejecutando una celda no más y haya menos margen de error y preguntas\n",
    "# si te parece ok, dejala y, si no, la borramos\n",
    "# los comentarios son para vos, después, borralos si te parece\n",
    "\n",
    "# descarga maltparser desde la url indicada en una carpeta llamada maltparser-1.9.2 (la crea)\n",
    "! wget -qO- http://maltparser.org/dist/maltparser-1.9.2.tar.gz | tar -xvz > /dev/null\n",
    "\n",
    "# descarga el modelo engmalt.poly-1.7 en la carpeta maltparser-1.9.2\n",
    "! wget -P maltparser-1.9.2 http://www.maltparser.org/mco/english_parser/engmalt.poly-1.7.mco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# !COMENTARIO\n",
    "# indica el path absoluto a donde se encuentra esta notebook\n",
    "# (por si alguien no está usando la virtual)\n",
    "# lo que también está bueno de os.pah.join es que, si alguien está usando windows, \n",
    "# donde las barras van al revés, os las pone bien y no van a tener que cambiarlas\n",
    "# no entiendo bien por qué hay que \n",
    "here = os.path.abspath('.')\n",
    "maltparser_folder = 'maltparser-1.9.2'\n",
    "os.environ['MALT_PARSER'] = os.path.join(here, maltparser_folder, '')\n",
    "os.environ['MALT_MODEL'] = os.path.join(here, maltparser_folder, 'engmalt.poly-1.7.mco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "maltParser = nltk.parse.malt.MaltParser(os.getenv('MALT_PARSER'), os.getenv('MALT_MODEL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['MALT_PARSER']=\"/home/grmf/Escritorio/seminario-gramaticas-formales/Clase-11/malt/maltparser-1.9.2/\"\n",
    "os.environ['MALT_MODEL']=\"/home/grmf/Escritorio/seminario-gramaticas-formales/Clase-11/malt/maltparser-1.9.2/engmalt.poly-1.7.mco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parserversion = '/home/grmf/Escritorio/seminario-gramaticas-formales/Clase-11/malt/maltparser-1.9.2/' # Define la versión del parser. \n",
    "langmodel = '/home/grmf/Escritorio/seminario-gramaticas-formales/Clase-11/malt/maltparser-1.9.2/engmalt.poly-1.7.mco'# Define el modelo entrenado poly\n",
    "#lamgmodel = 'engmalt.linear-1.7.mco' # Define el modelo entrenado linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maltParser = nltk.parse.malt.MaltParser(parserversion, langmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " my mother lives in another city\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lives my mother (in (city another)))\n"
     ]
    }
   ],
   "source": [
    "oracion8 = input()\n",
    "stemma = maltParser.parse_one(oracion8.split()).tree()\n",
    "print(stemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PystanfordDependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parser de Stanford se mudó a un nuevo repositorio y cambió su nombre a Stanza. Se puede encontrar la documentación en [https://stanfordnlp.github.io/stanza/](https://stanfordnlp.github.io/stanza/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "from stanza.models.common.doc import Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stanza.download('es') # Baja el modelo para el españo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-10 18:02:21 INFO: Loading these models for language: es (Spanish):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ancora  |\n",
      "| mwt       | ancora  |\n",
      "| pos       | ancora  |\n",
      "| lemma     | ancora  |\n",
      "| depparse  | ancora  |\n",
      "| ner       | conll02 |\n",
      "=======================\n",
      "\n",
      "2022-06-10 18:02:21 INFO: Use device: cpu\n",
      "2022-06-10 18:02:21 INFO: Loading: tokenize\n",
      "2022-06-10 18:02:21 INFO: Loading: mwt\n",
      "2022-06-10 18:02:21 INFO: Loading: pos\n",
      "2022-06-10 18:02:22 INFO: Loading: lemma\n",
      "2022-06-10 18:02:22 INFO: Loading: depparse\n",
      "2022-06-10 18:02:23 INFO: Loading: ner\n",
      "2022-06-10 18:02:24 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stanza.pipeline.core.Pipeline at 0x11fa13910>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('es') # Inicializa el modelo de español (con su pipeline de anotación)\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  [\n",
       "    {\n",
       "      \"id\": 1,\n",
       "      \"text\": \"Pablo\",\n",
       "      \"lemma\": \"Pablo\",\n",
       "      \"upos\": \"PROPN\",\n",
       "      \"xpos\": \"PROPN\",\n",
       "      \"head\": 3,\n",
       "      \"deprel\": \"nsubj\",\n",
       "      \"misc\": \"start_char=0|end_char=5\",\n",
       "      \"ner\": \"B-PER\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 2,\n",
       "      \"text\": \"Neruda\",\n",
       "      \"lemma\": \"Neruda\",\n",
       "      \"upos\": \"PROPN\",\n",
       "      \"xpos\": \"PROPN\",\n",
       "      \"head\": 1,\n",
       "      \"deprel\": \"flat\",\n",
       "      \"misc\": \"start_char=6|end_char=12\",\n",
       "      \"ner\": \"E-PER\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 3,\n",
       "      \"text\": \"escribe\",\n",
       "      \"lemma\": \"escribir\",\n",
       "      \"upos\": \"VERB\",\n",
       "      \"xpos\": \"VERB\",\n",
       "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
       "      \"head\": 0,\n",
       "      \"deprel\": \"root\",\n",
       "      \"misc\": \"start_char=13|end_char=20\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 4,\n",
       "      \"text\": \"poemas\",\n",
       "      \"lemma\": \"poema\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NOUN\",\n",
       "      \"feats\": \"Gender=Masc|Number=Plur\",\n",
       "      \"head\": 3,\n",
       "      \"deprel\": \"obj\",\n",
       "      \"misc\": \"start_char=21|end_char=27\",\n",
       "      \"ner\": \"O\"\n",
       "    }\n",
       "  ]\n",
       "]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Pablo Neruda escribe poemas\") # Anota una oración\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\n",
      "  \"text\": \"Pablo Neruda\",\n",
      "  \"type\": \"PER\",\n",
      "  \"start_char\": 0,\n",
      "  \"end_char\": 12\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "print(doc.entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Pablo', 3, 'nsubj')\n",
      "('Neruda', 1, 'flat')\n",
      "('escribe', 0, 'root')\n",
      "('poemas', 3, 'obj')\n"
     ]
    }
   ],
   "source": [
    "doc.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({\n",
       "    \"id\": 3,\n",
       "    \"text\": \"escribe\",\n",
       "    \"lemma\": \"escribir\",\n",
       "    \"upos\": \"VERB\",\n",
       "    \"xpos\": \"VERB\",\n",
       "    \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
       "    \"head\": 0,\n",
       "    \"deprel\": \"root\",\n",
       "    \"misc\": \"start_char=13|end_char=20\"\n",
       "  },\n",
       "  'nsubj',\n",
       "  {\n",
       "    \"id\": 1,\n",
       "    \"text\": \"Pablo\",\n",
       "    \"lemma\": \"Pablo\",\n",
       "    \"upos\": \"PROPN\",\n",
       "    \"xpos\": \"PROPN\",\n",
       "    \"head\": 3,\n",
       "    \"deprel\": \"nsubj\",\n",
       "    \"misc\": \"start_char=0|end_char=5\"\n",
       "  }),\n",
       " ({\n",
       "    \"id\": 1,\n",
       "    \"text\": \"Pablo\",\n",
       "    \"lemma\": \"Pablo\",\n",
       "    \"upos\": \"PROPN\",\n",
       "    \"xpos\": \"PROPN\",\n",
       "    \"head\": 3,\n",
       "    \"deprel\": \"nsubj\",\n",
       "    \"misc\": \"start_char=0|end_char=5\"\n",
       "  },\n",
       "  'flat',\n",
       "  {\n",
       "    \"id\": 2,\n",
       "    \"text\": \"Neruda\",\n",
       "    \"lemma\": \"Neruda\",\n",
       "    \"upos\": \"PROPN\",\n",
       "    \"xpos\": \"PROPN\",\n",
       "    \"head\": 1,\n",
       "    \"deprel\": \"flat\",\n",
       "    \"misc\": \"start_char=6|end_char=12\"\n",
       "  }),\n",
       " ({\n",
       "    \"id\": 0,\n",
       "    \"text\": \"ROOT\"\n",
       "  },\n",
       "  'root',\n",
       "  {\n",
       "    \"id\": 3,\n",
       "    \"text\": \"escribe\",\n",
       "    \"lemma\": \"escribir\",\n",
       "    \"upos\": \"VERB\",\n",
       "    \"xpos\": \"VERB\",\n",
       "    \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
       "    \"head\": 0,\n",
       "    \"deprel\": \"root\",\n",
       "    \"misc\": \"start_char=13|end_char=20\"\n",
       "  }),\n",
       " ({\n",
       "    \"id\": 3,\n",
       "    \"text\": \"escribe\",\n",
       "    \"lemma\": \"escribir\",\n",
       "    \"upos\": \"VERB\",\n",
       "    \"xpos\": \"VERB\",\n",
       "    \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
       "    \"head\": 0,\n",
       "    \"deprel\": \"root\",\n",
       "    \"misc\": \"start_char=13|end_char=20\"\n",
       "  },\n",
       "  'obj',\n",
       "  {\n",
       "    \"id\": 4,\n",
       "    \"text\": \"poemas\",\n",
       "    \"lemma\": \"poema\",\n",
       "    \"upos\": \"NOUN\",\n",
       "    \"xpos\": \"NOUN\",\n",
       "    \"feats\": \"Gender=Masc|Number=Plur\",\n",
       "    \"head\": 3,\n",
       "    \"deprel\": \"obj\",\n",
       "    \"misc\": \"start_char=21|end_char=27\"\n",
       "  })]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.sentences[0].dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  [\n",
       "    {\n",
       "      \"id\": 1,\n",
       "      \"text\": \"el\",\n",
       "      \"lemma\": \"el\",\n",
       "      \"upos\": \"DET\",\n",
       "      \"xpos\": \"DET\",\n",
       "      \"feats\": \"Definite=Def|Gender=Masc|Number=Sing|PronType=Art\",\n",
       "      \"head\": 2,\n",
       "      \"deprel\": \"det\",\n",
       "      \"misc\": \"start_char=0|end_char=2\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 2,\n",
       "      \"text\": \"poeta\",\n",
       "      \"lemma\": \"poeta\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NOUN\",\n",
       "      \"feats\": \"Gender=Masc|Number=Sing\",\n",
       "      \"head\": 4,\n",
       "      \"deprel\": \"nsubj\",\n",
       "      \"misc\": \"start_char=3|end_char=8\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 3,\n",
       "      \"text\": \"chileno\",\n",
       "      \"lemma\": \"chileno\",\n",
       "      \"upos\": \"ADJ\",\n",
       "      \"xpos\": \"ADJ\",\n",
       "      \"feats\": \"Gender=Masc|Number=Sing\",\n",
       "      \"head\": 2,\n",
       "      \"deprel\": \"amod\",\n",
       "      \"misc\": \"start_char=9|end_char=16\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 4,\n",
       "      \"text\": \"escribe\",\n",
       "      \"lemma\": \"escribir\",\n",
       "      \"upos\": \"VERB\",\n",
       "      \"xpos\": \"VERB\",\n",
       "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
       "      \"head\": 0,\n",
       "      \"deprel\": \"root\",\n",
       "      \"misc\": \"start_char=17|end_char=24\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 5,\n",
       "      \"text\": \"poemas\",\n",
       "      \"lemma\": \"poema\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NOUN\",\n",
       "      \"feats\": \"Gender=Masc|Number=Plur\",\n",
       "      \"head\": 4,\n",
       "      \"deprel\": \"obj\",\n",
       "      \"misc\": \"start_char=25|end_char=31\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 6,\n",
       "      \"text\": \"y\",\n",
       "      \"lemma\": \"y\",\n",
       "      \"upos\": \"CCONJ\",\n",
       "      \"xpos\": \"CCONJ\",\n",
       "      \"head\": 10,\n",
       "      \"deprel\": \"cc\",\n",
       "      \"misc\": \"start_char=32|end_char=33\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 7,\n",
       "      \"text\": \"la\",\n",
       "      \"lemma\": \"el\",\n",
       "      \"upos\": \"DET\",\n",
       "      \"xpos\": \"DET\",\n",
       "      \"feats\": \"Definite=Def|Gender=Fem|Number=Sing|PronType=Art\",\n",
       "      \"head\": 8,\n",
       "      \"deprel\": \"det\",\n",
       "      \"misc\": \"start_char=34|end_char=36\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 8,\n",
       "      \"text\": \"mujer\",\n",
       "      \"lemma\": \"mujer\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NOUN\",\n",
       "      \"feats\": \"Gender=Fem|Number=Sing\",\n",
       "      \"head\": 10,\n",
       "      \"deprel\": \"nsubj\",\n",
       "      \"misc\": \"start_char=37|end_char=42\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 9,\n",
       "      \"text\": \"alemana\",\n",
       "      \"lemma\": \"alemán\",\n",
       "      \"upos\": \"ADJ\",\n",
       "      \"xpos\": \"ADJ\",\n",
       "      \"feats\": \"Gender=Fem|Number=Sing\",\n",
       "      \"head\": 8,\n",
       "      \"deprel\": \"amod\",\n",
       "      \"misc\": \"start_char=43|end_char=50\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 10,\n",
       "      \"text\": \"corta\",\n",
       "      \"lemma\": \"cortar\",\n",
       "      \"upos\": \"VERB\",\n",
       "      \"xpos\": \"VERB\",\n",
       "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
       "      \"head\": 4,\n",
       "      \"deprel\": \"conj\",\n",
       "      \"misc\": \"start_char=51|end_char=56\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 11,\n",
       "      \"text\": \"un\",\n",
       "      \"lemma\": \"uno\",\n",
       "      \"upos\": \"DET\",\n",
       "      \"xpos\": \"DET\",\n",
       "      \"feats\": \"Definite=Ind|Gender=Masc|Number=Sing|PronType=Art\",\n",
       "      \"head\": 12,\n",
       "      \"deprel\": \"det\",\n",
       "      \"misc\": \"start_char=57|end_char=59\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 12,\n",
       "      \"text\": \"kuchen\",\n",
       "      \"lemma\": \"kuchen\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NOUN\",\n",
       "      \"feats\": \"Gender=Masc|Number=Sing\",\n",
       "      \"head\": 10,\n",
       "      \"deprel\": \"obj\",\n",
       "      \"misc\": \"start_char=60|end_char=66\",\n",
       "      \"ner\": \"O\"\n",
       "    }\n",
       "  ]\n",
       "]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"el poeta chileno escribe poemas y la mujer alemana corta un kuchen\")\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('el', 2, 'det')\n",
      "('poeta', 4, 'nsubj')\n",
      "('chileno', 2, 'amod')\n",
      "('escribe', 0, 'root')\n",
      "('poemas', 4, 'obj')\n",
      "('y', 10, 'cc')\n",
      "('la', 8, 'det')\n",
      "('mujer', 10, 'nsubj')\n",
      "('alemana', 8, 'amod')\n",
      "('corta', 4, 'conj')\n",
      "('un', 12, 'det')\n",
      "('kuchen', 10, 'obj')\n"
     ]
    }
   ],
   "source": [
    "doc.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_entidades(stanza_oracion):\n",
    "    entidades = [] # Creo una lista vacía donde voy a guardar todas las entidades que encuentre en la oración\n",
    "    for dependencia in stanza_oracion.dependencies: # Recorro las dependencias\n",
    "        regidor, relacion, dependiente = dependencia # Las dependencias son tuplas de tres elementos que puedo separar\n",
    "                                                     # en variables\n",
    "        if regidor.deprel == \"nsubj\": # Asumimos que queremos encontrar los sujetos, pero podríamos comparar por PoS\n",
    "                                      # ¿Cómo?\n",
    "            entidad = [regidor]       # Creo una lista cuyo miembro inicial es el nucleo de la construccion\n",
    "            for palabra in stanza_oracion.words: # Vuelvo a recorrer las palabras de la oración para encontrar\n",
    "                                                 # todos los dependientes del sujeto, sean anteriores o posteriores\n",
    "                if palabra.head == int(regidor.id): # Si el nucleo/regidor/head de una palabra coincide con el id\n",
    "                    entidad.append(palabra)         # del núcleo de mi construcción, lo sumo a la lista de la entidad\n",
    "            entidad = sorted(entidad, key=lambda x: x.id) # Ordeno la lista resultante por su número de id para \n",
    "                                                          # mantener la linealidad del texto.\n",
    "            if entidad not in entidades:            # Chequeo que la entidad ya no exista en mi lista porque\n",
    "                entidades.append(entidad)           # el regidor puede aparecer en más de una dependencia.\n",
    "            \n",
    "    return [\" \".join([palabra.text for palabra in entidad]) for entidad in entidades] # Me quedo únicamente con el \n",
    "                                                       # texto de cada objeto Word y lo devuelvo unido por entidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['el poeta chileno', 'la mujer alemana']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraer_entidades(doc.sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.sentences[0].words[0].head"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
